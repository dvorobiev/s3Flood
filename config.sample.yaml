# Пример конфига запуска s3flood. Скопируйте в config.local.yaml и подставьте свои значения.
run:
  profile: write  # профиль по умолчанию; при запуске можно переопределить через CLI или меню (write/read/mixed)
  client: awscli
  # Один endpoint...
  endpoint: "http://127.0.0.1:9000"
  # ...или кластерный режим (см. endpoint_mode: round-robin|random)
  # endpoints:
  #   - "http://127.0.0.1:9000"
  #   - "http://127.0.0.2:9000"
  # endpoint_mode: round-robin
  bucket: "your-bucket-name"
  # Варианты аутентификации:
  # 1. Указать access/secret ключи вручную (как ниже) — не храните их в репозитории.
  # 2. Либо удалить access_key/secret_key и прописать aws_profile (или воспользоваться AWS CLI профилем по умолчанию).
  # access_key: "YOUR_ACCESS_KEY"
  # secret_key: "YOUR_SECRET_KEY"
  aws_profile: default
  threads: 8
  data_dir: "./loadset/data"
  report: "out.json"
  metrics: "out.csv"
  # infinite: false  # Бесконечный режим: после завершения всех файлов начинать заново
  # Параметры для mixed профиля
  # mixed_read_ratio: 0.7  # Доля операций чтения (0.0-1.0), по умолчанию 0.7 для mixed
  # Паттерны нагрузки
  # pattern: sustained  # sustained | bursty
  # burst_duration_sec: 10.0  # Длительность всплеска в секундах для bursty
  # burst_intensity_multiplier: 10.0  # Множитель интенсивности для bursty
  # Управление очередью
  # queue_limit: 1000  # Максимальный размер очереди операций
  # max_retries: 3  # Количество повторов при ошибке
  # retry_backoff_base: 2.0  # Базовый множитель для экспоненциального backoff при повторах (по умолчанию: 2.0, т.е. задержки: 1s, 2s, 4s между попытками)
  # Порядок обработки файлов
  order: random  # sequential (сначала маленькие) или random (случайный порядок)
  # Уникальные имена объектов в бакете (добавляет постфикс и не перезаписывает предыдущие файлы)
  unique_remote_names: false

