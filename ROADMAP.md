## Roadmap

### Реализованные GitHub Actions

В проекте уже настроены следующие автоматизированные workflow:

1. **CI** (`.github/workflows/ci.yml`):
   - Запускается на каждый push в `main` и на pull requests
   - Тестирует на Linux (Ubuntu latest)
   - Запускает MinIO в Docker, создаёт датасет, выполняет smoke-тест (write профиль)
   - Загружает артефакты с отчётами

2. **Release** (`.github/workflows/release.yml`):
   - Запускается при создании тега `v*`
   - Собирает wheel и sdist через `python -m build`
   - Автоматически извлекает release notes из CHANGELOG.md
   - Создаёт GitHub Release с артефактами

3. **Windows Bundle** (`.github/workflows/windows-bundle.yml`):
   - Запускается при создании тега или вручную через `workflow_dispatch`
   - Собирает `s3flood.exe` через PyInstaller на Windows runner
   - Создаёт `s3flood-windows.zip` с exe, README и config.sample.yaml
   - Автоматически прикрепляет к GitHub Release

4. **Windows Portable** (`.github/workflows/windows-portable.yml`):
   - Запускается при создании тега или вручную через `workflow_dispatch`
   - Собирает portable дистрибутив с Python embedded (3.11.9)
   - Включает все зависимости, создаёт batch-скрипты для запуска
   - Создаёт `s3flood-windows-portable.zip` и прикрепляет к релизу

### Высокий приоритет
- [x] **Автотесты: pytest + smoke-сценарий против MinIO в CI (Linux и Windows).** — частично реализовано
  
  **Что это:** Автоматизированные тесты для проверки работоспособности s3flood перед каждым коммитом/релизом.
  
  **Что уже реализовано:**
  - ✅ **CI workflow** (`.github/workflows/ci.yml`): автоматический smoke-тест на Linux
    - Запускает MinIO в Docker контейнере
    - Создаёт минимальный датасет (5 small, 3 medium, 1 large файл)
    - Запускает профиль `write` с 2 потоками против MinIO
    - Загружает артефакты (out.json, out.csv) для анализа
    - Триггерится на push в `main` и на pull requests
  - ✅ **Release workflow** (`.github/workflows/release.yml`): автоматическая сборка и публикация релизов
    - Собирает wheel и sdist при создании тега `v*`
    - Автоматически извлекает release notes из CHANGELOG.md
    - Создаёт GitHub Release с артефактами
  - ✅ **Windows bundle workflow** (`.github/workflows/windows-bundle.yml`): сборка Windows exe
    - Собирает `s3flood.exe` через PyInstaller
    - Создаёт ZIP-архив с exe, README и config.sample.yaml
    - Автоматически прикрепляет к релизу при создании тега
  - ✅ **Windows portable workflow** (`.github/workflows/windows-portable.yml`): portable дистрибутив
    - Собирает portable версию с Python embedded (3.11.9)
    - Включает все зависимости и s3flood
    - Создаёт ZIP с batch-скриптами для запуска
    - Автоматически прикрепляет к релизу при создании тега
  
  **Что осталось сделать:**
  - [ ] Добавить Windows runner в CI workflow для тестирования на Windows
  - [ ] Написать pytest-тесты (сейчас используется интеграционный smoke-тест через CLI)
  - [ ] Расширить тестовое покрытие: добавить тесты для профилей `read` и `mixed`
  - [ ] Проверка метрик: автоматическая валидация структуры CSV и JSON отчётов
  - [ ] Интеграция с pytest для более структурированного тестирования
- [x] Профили нагрузки: `read-heavy`, `write-heavy`, `mixed` (ранее `mixed-70-30`), паттерны `sustained|bursty` — реализовано.
- [x] Тест чтения из бакета (поток в `/dev/null`, без нагрузки на диск) — реализовано в профиле `write-heavy`.
- [x] Смешанные режимы (одновременный upload/download, общая очередь) — реализовано в профиле `mixed`.
- [ ] Удаление загруженных объектов после завершения профиля или по опции `--cleanup`.
- [x] Ретраи с экспоненциальным backoff, таймауты, лимиты очередей — реализовано.
- [x] Кластерный режим: чтение через тот же endpoint, через который был записан объект — реализовано.

### Средний приоритет
- [ ] **Интерфейс `Runner` и дополнительные клиенты: `s5cmd`, `rclone`, (в перспективе — кастомные агенты).**
  
  **Что это:** Абстракция над S3-клиентами, позволяющая использовать не только AWS CLI, но и альтернативные инструменты для операций с S3.
  
  **Как планируем реализовать:**
  - Создать абстрактный интерфейс `Runner` (или `S3Client`) с методами: `upload()`, `download()`, `list_objects()`, `delete_object()`
  - Реализовать конкретные классы:
    - `AWSCLIRunner` (текущая реализация через `aws s3 cp` / `aws s3api`)
    - `S5cmdRunner` (через `s5cmd cp` — быстрый параллельный клиент)
    - `RcloneRunner` (через `rclone copy` — универсальный инструмент)
  - Добавить в конфиг поле `client: awscli|s5cmd|rclone` (уже есть в схеме, но используется только `awscli`)
  - Адаптировать логику в `executor.py` для работы через абстракцию вместо прямых вызовов `subprocess.run(["aws", ...])`
  - Преимущества: возможность сравнения производительности разных клиентов, использование более быстрых инструментов (s5cmd), гибкость выбора инструмента под задачу
- [x] Расширенный CLI/TUI: меню выбора профиля, статуса и конфигов — реализовано в интерактивном меню (`--interactive`).
- [ ] **Улучшение визуализации текущих метрик в дашборде.**
  
  **Что это:** Более наглядное и информативное отображение метрик в реальном времени во время выполнения теста.
  
  **Как планируем реализовать:**
  - **Улучшение дашборда:**
    - Добавить графики скорости в реальном времени (ASCII-графики или sparklines через `rich`)
    - Визуализация распределения скоростей по операциям (гистограмма или box plot)
    - Цветовая индикация производительности (зелёный/жёлтый/красный в зависимости от скорости)
    - Более детальная информация о текущих операциях: прогресс-бары для больших файлов, ETA для каждой операции
  - **Расширение секции Recent ops:**
    - Группировка операций по статусу (успешные/ошибки)
    - Сортировка по скорости или размеру
    - Фильтрация по типу операции (upload/download)
  - **Дополнительные метрики в дашборде:**
    - Текущая латентность (p50/p90) для последних N операций
    - График изменения скорости во времени
    - Статистика по группам файлов (small/medium/large) отдельно
  - **Интерактивный просмотр метрик:**
    - Возможность паузы/продолжения обновления дашборда
    - Экспорт текущего состояния метрик в файл прямо во время выполнения
- [ ] Документация: примеры конфигов (`examples/configs/*.yaml`), подробные гайды по профилям, Quickstart Linux/Windows.
- [ ] **Поддержка чтения/записи с ограничениями IOPS/throughput, базовый throttling.**
  
  **Что это:** Возможность ограничить скорость операций (например, симулировать медленное соединение или тестировать поведение при ограниченной пропускной способности).
  
  **Как планируем реализовать:**
  - Добавить в конфиг параметры:
    - `max_throughput_mbps: float | None` — максимальная скорость в MB/s (общая для всех потоков)
    - `max_iops: int | None` — максимальное количество операций в секунду
    - `throttle_per_thread: bool` — применять лимиты на каждый поток отдельно или глобально
  - Реализовать throttling механизм:
    - Использовать `time.sleep()` для задержек между операциями или внутри операций (для throughput)
    - Для IOPS: счётчик операций в секунду, блокировка при превышении лимита
    - Для throughput: измерение скорости передачи данных, паузы для соблюдения лимита
  - Интеграция в `executor.py`: проверка лимитов перед/во время выполнения операций
  - Применение: симуляция реальных сетевых условий, тестирование устойчивости S3-бэкенда при ограниченной пропускной способности, нагрузочное тестирование с контролируемой интенсивностью
- [ ] Настройки параметров AWS CLI: размер чанка (multipart chunk size), multipart threshold, max concurrent requests и другие параметры производительности.

### Низкий приоритет / дальше
- [x] **PyInstaller/standalone сборки для Linux/Windows.** — реализовано для Windows
  
  **Что реализовано:**
  - ✅ **Windows exe через PyInstaller** (workflow `windows-bundle.yml`): автоматическая сборка `s3flood.exe` с включёнными зависимостями
  - ✅ **Windows portable дистрибутив** (workflow `windows-portable.yml`): сборка portable версии с Python embedded, не требующей установки Python на целевой машине
  - ✅ Автоматическое прикрепление к GitHub Release при создании тега
  
  **Что осталось:**
  - [ ] Standalone сборки для Linux (аналогично Windows portable)
  - [ ] Локальные скрипты сборки для разработчиков (уже есть `build-windows-portable.sh`)
- [ ] **Расширенные распределения наборов данных (Pareto/Zipf).**
  
  **Что это:** Генерация датасетов с реалистичными распределениями размеров файлов, имитирующими реальные паттерны использования (большинство файлов маленькие, но есть несколько очень больших).
  
  **Как планируем реализовать:**
  - **Pareto распределение (80/20 правило):**
    - 80% файлов маленькие, 20% — большие
    - Параметры: `pareto_alpha` (степень неравномерности), `pareto_min_size`, `pareto_max_size`
    - Использование библиотеки `numpy.random.pareto()` для генерации размеров
  - **Zipf распределение:**
    - Ещё более реалистичное распределение для веб-контента и файловых систем
    - Параметры: `zipf_a` (параметр формы), диапазон размеров
    - Использование `numpy.random.zipf()` для генерации
  - **Интеграция в `dataset.py`:**
    - Добавить опцию `distribution: uniform|pareto|zipf` в параметры генерации датасета
    - При выборе `pareto`/`zipf` — генерировать размеры файлов по соответствующему распределению вместо равномерного
    - Сохранять метаданные о распределении в датасете для воспроизводимости
  - **Применение:** более реалистичные тесты, имитация реальных рабочих нагрузок (например, веб-сервер с большим количеством маленьких статических файлов и несколькими большими медиа-файлами)
- [ ] **Расширенные метрики: P50/P90/P99 для всех операций, экспорт в Prometheus-совместимый формат.**
  
  **Что это:** Детальная статистика по процентилям латентности и скорости, а также интеграция с системами мониторинга.
  
  **Как планируем реализовать:**
  - **Процентили латентности:**
    - Расширить класс `Metrics` для расчёта P50/P90/P95/P99 по `latency_ms` для upload и download операций отдельно
    - Добавить расчёт процентилей по скорости (MB/s) для успешных операций
    - Выводить в дашборд и в итоговый JSON-отчёт (`report.json`)
  - **Prometheus-совместимый экспорт:**
    - Добавить опцию `--metrics-format prometheus` или `metrics_format: prometheus` в конфиг
    - Генерировать файл в формате Prometheus text-based exposition format (`.prom` файл)
    - Метрики: `s3flood_operations_total{op="upload|download",status="ok|err"}`, `s3flood_bytes_total{op="upload|download"}`, `s3flood_latency_seconds{op="upload|download",quantile="0.5|0.9|0.99"}`, `s3flood_speed_mbps{op="upload|download"}`
    - Возможность отправки метрик в Pushgateway или через HTTP endpoint для scraping
  - **Интеграция с Grafana:** пример дашборда для визуализации метрик из Prometheus
- [x] Улучшенный TUI (rich/textual) с графиками в реальном времени — базовый TUI на rich/questionary реализован (графики в реальном времени — в планах).


