name: CI

on:
  push:
    branches: [ "feature/cli-min", "main" ]
  pull_request:
    branches: [ "feature/cli-min", "main" ]

jobs:
  linux:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install awscli
        run: |
          pipx install awscli
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Install project
        run: |
          pip install -U pip
          pip install -e .

      - name: Start MinIO
        run: |
          docker run -d --name minio \
            -p 9000:9000 -p 9001:9001 \
            -e MINIO_ROOT_USER=minioadmin \
            -e MINIO_ROOT_PASSWORD=minioadmin \
            quay.io/minio/minio server /data --console-address ":9001"

      - name: Wait for MinIO
        run: |
          for i in {1..30}; do
            if curl -sSf http://127.0.0.1:9000 >/dev/null; then exit 0; fi
            sleep 2
          done
          echo "MinIO not responding" && exit 1

      - name: Create bucket
        env:
          AWS_ACCESS_KEY_ID: minioadmin
          AWS_SECRET_ACCESS_KEY: minioadmin
          AWS_EC2_METADATA_DISABLED: "true"
        run: |
          aws --endpoint-url http://127.0.0.1:9000 s3 mb s3://test-bucket || true

      - name: Generate small dataset
        run: |
          python -m s3flood dataset-create --path ./loadset --use-symlinks --min-counts 5,3,1 --group-limits 1MB,2MB,4MB --safety-ratio 0.01

      - name: Run write-heavy profile (smoke)
        env:
          AWS_ACCESS_KEY_ID: minioadmin
          AWS_SECRET_ACCESS_KEY: minioadmin
          AWS_EC2_METADATA_DISABLED: "true"
        run: |
          python -m s3flood run \
            --profile write-heavy \
            --client awscli \
            --threads 2 \
            --endpoint http://127.0.0.1:9000 \
            --bucket test-bucket \
            --access-key minioadmin \
            --secret-key minioadmin \
            --data-dir ./loadset/data \
            --report out.json \
            --metrics out.csv

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: s3flood-reports
          path: |
            out.json
            out.csv

